{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAD Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [23, 10]\n",
    "plt.rcParams['axes.axisbelow'] = True\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from texttable import Texttable\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255120, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ekervella/Dropbox/GitHub/vad/vad_data/csv/103-1240-0001.csv')\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>-192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000063</th>\n",
       "      <td>-146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000125</th>\n",
       "      <td>-220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000188</th>\n",
       "      <td>-267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000250</th>\n",
       "      <td>-377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           value  target\n",
       "timestamp               \n",
       "0.000000    -192       0\n",
       "0.000063    -146       0\n",
       "0.000125    -220       0\n",
       "0.000188    -267       0\n",
       "0.000250    -377       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of voice activity: 87.87%\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of voice activity: {}%'.format(round(df['target'].sum()/df.shape[0]*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['value']]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, shuffle=True, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = RandomOverSampler(random_state=7)\n",
    "X_train_b, y_train_b = resampler.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return(tp/(tp+fp))\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return(tp/(tp+fn))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return((tp+tn)/(tn+fp+fn+tp))\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    return(2*p*r/(p+r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_predictor(X):\n",
    "    return([1]*X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=7, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=7)\n",
    "logreg.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=7,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=7)\n",
    "rf.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=7, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=7)\n",
    "xgb.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline Predictor ---\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "|                                |  Precision   |    Recall    |   Accuracy   |   F1 Score   |\n",
      "+================================+==============+==============+==============+==============+\n",
      "| On Train (Over Resampled)      | 0.500        | 1            | 0.500        | 0.667        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "| On Test (Imbalanced)           | 0.879        | 1            | 0.879        | 0.936        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print('--- Baseline Predictor ---')\n",
    "table = Texttable()\n",
    "rows = []\n",
    "rows.append(['', 'Precision', 'Recall', 'Accuracy', 'F1 Score'])\n",
    "rows.append(['On Train (Over Resampled)', round(precision(y_train_b, baseline_predictor(X_train_b)), 3), \n",
    "             round(recall(y_train_b, baseline_predictor(X_train_b)), 3), round(accuracy(y_train_b, baseline_predictor(X_train_b)), 3),\n",
    "             round(f1_score(y_train_b, baseline_predictor(X_train_b)), 3)])\n",
    "rows.append(['On Test (Imbalanced)', round(precision(y_test, baseline_predictor(X_test)), 3), round(recall(y_test, baseline_predictor(X_test)), 3), \n",
    "             round(accuracy(y_test, baseline_predictor(X_test)), 3), round(f1_score(y_test, baseline_predictor(X_test)), 3)])\n",
    "\n",
    "table.add_rows(rows)\n",
    "table.set_cols_width([30, 12, 12, 12, 12])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Logistic Regression ---\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "|                                |  Precision   |    Recall    |   Accuracy   |   F1 Score   |\n",
      "+================================+==============+==============+==============+==============+\n",
      "| On Train (Over Resampled)      | 0.495        | 0.472        | 0.495        | 0.483        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "| On Test (Imbalanced)           | 0.877        | 0.471        | 0.477        | 0.613        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print('--- Logistic Regression ---')\n",
    "model = logreg\n",
    "table = Texttable()\n",
    "rows = []\n",
    "rows.append(['', 'Precision', 'Recall', 'Accuracy', 'F1 Score'])\n",
    "rows.append(['On Train (Over Resampled)', round(precision(y_train_b, model.predict(X_train_b)), 3), \n",
    "             round(recall(y_train_b, model.predict(X_train_b)), 3), round(accuracy(y_train_b, model.predict(X_train_b)), 3),\n",
    "             round(f1_score(y_train_b, model.predict(X_train_b)), 3)])\n",
    "rows.append(['On Test (Imbalanced)', round(precision(y_test, model.predict(X_test)), 3), round(recall(y_test, model.predict(X_test)), 3), \n",
    "             round(accuracy(y_test, model.predict(X_test)), 3), round(f1_score(y_test, model.predict(X_test)), 3)])\n",
    "\n",
    "table.add_rows(rows)\n",
    "table.set_cols_width([30, 12, 12, 12, 12])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Decision Tree Classifier ---\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "|                                |  Precision   |    Recall    |   Accuracy   |   F1 Score   |\n",
      "+================================+==============+==============+==============+==============+\n",
      "| On Train (Over Resampled)      | 0.891        | 0.517        | 0.727        | 0.654        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "| On Test (Imbalanced)           | 0.982        | 0.514        | 0.564        | 0.675        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print('--- Decision Tree Classifier ---')\n",
    "model = tree\n",
    "table = Texttable()\n",
    "rows = []\n",
    "rows.append(['', 'Precision', 'Recall', 'Accuracy', 'F1 Score'])\n",
    "rows.append(['On Train (Over Resampled)', round(precision(y_train_b, model.predict(X_train_b)), 3), \n",
    "             round(recall(y_train_b, model.predict(X_train_b)), 3), round(accuracy(y_train_b, model.predict(X_train_b)), 3),\n",
    "             round(f1_score(y_train_b, model.predict(X_train_b)), 3)])\n",
    "rows.append(['On Test (Imbalanced)', round(precision(y_test, model.predict(X_test)), 3), round(recall(y_test, model.predict(X_test)), 3), \n",
    "             round(accuracy(y_test, model.predict(X_test)), 3), round(f1_score(y_test, model.predict(X_test)), 3)])\n",
    "\n",
    "table.add_rows(rows)\n",
    "table.set_cols_width([30, 12, 12, 12, 12])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest Classifier ---\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "|                                |  Precision   |    Recall    |   Accuracy   |   F1 Score   |\n",
      "+================================+==============+==============+==============+==============+\n",
      "| On Train (Over Resampled)      | 0.890        | 0.517        | 0.727        | 0.654        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "| On Test (Imbalanced)           | 0.982        | 0.514        | 0.564        | 0.675        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print('--- Random Forest Classifier ---')\n",
    "model = rf\n",
    "table = Texttable()\n",
    "rows = []\n",
    "rows.append(['', 'Precision', 'Recall', 'Accuracy', 'F1 Score'])\n",
    "rows.append(['On Train (Over Resampled)', round(precision(y_train_b, model.predict(X_train_b)), 3), \n",
    "             round(recall(y_train_b, model.predict(X_train_b)), 3), round(accuracy(y_train_b, model.predict(X_train_b)), 3),\n",
    "             round(f1_score(y_train_b, model.predict(X_train_b)), 3)])\n",
    "rows.append(['On Test (Imbalanced)', round(precision(y_test, model.predict(X_test)), 3), round(recall(y_test, model.predict(X_test)), 3), \n",
    "             round(accuracy(y_test, model.predict(X_test)), 3), round(f1_score(y_test, model.predict(X_test)), 3)])\n",
    "\n",
    "table.add_rows(rows)\n",
    "table.set_cols_width([30, 12, 12, 12, 12])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- XGBoost Classifier ---\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "|                                |  Precision   |    Recall    |   Accuracy   |   F1 Score   |\n",
      "+================================+==============+==============+==============+==============+\n",
      "| On Train (Over Resampled)      | 0.889        | 0.516        | 0.726        | 0.653        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n",
      "| On Test (Imbalanced)           | 0.983        | 0.513        | 0.565        | 0.675        |\n",
      "+--------------------------------+--------------+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "print('--- XGBoost Classifier ---')\n",
    "model = xgb\n",
    "table = Texttable()\n",
    "rows = []\n",
    "rows.append(['', 'Precision', 'Recall', 'Accuracy', 'F1 Score'])\n",
    "rows.append(['On Train (Over Resampled)', round(precision(y_train_b, model.predict(X_train_b)), 3), \n",
    "             round(recall(y_train_b, model.predict(X_train_b)), 3), round(accuracy(y_train_b, model.predict(X_train_b)), 3),\n",
    "             round(f1_score(y_train_b, model.predict(X_train_b)), 3)])\n",
    "rows.append(['On Test (Imbalanced)', round(precision(y_test, model.predict(X_test.values)), 3), round(recall(y_test, model.predict(X_test.values)), 3), \n",
    "             round(accuracy(y_test, model.predict(X_test.values)), 3), round(f1_score(y_test, model.predict(X_test.values)), 3)])\n",
    "\n",
    "table.add_rows(rows)\n",
    "table.set_cols_width([30, 12, 12, 12, 12])\n",
    "print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
